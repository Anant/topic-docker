Big Data technologies can all be dockerized or composed in a docker composition. Some of these resources below should bring some light into how to do this.



Resources
- [Big Data in Containers: Hadoop Spark in Docker and Mesos](https://www.slideshare.net/HeikoLoewe1/big-data-in-container-hadoop-spark-in-docker-and-mesos)
- [Github: Dockerized Spark](https://github.com/gettyimages/docker-spark)
- [Github: Dockerized Spark + HDFS](https://github.com/vkorukanti/spark-docker-compose)
- [Github: Dockerized Spark Cluster Deployer](https://github.com/DataToKnowledge/spark-cluster-deploy)
- [Article: Scalable Spark/HDFS Workbench using Docker](https://www.big-data-europe.eu/scalable-sparkhdfs-workbench-using-docker/)
- [Github: Dockerized Zeppelin Notebook](https://github.com/dylanmei/docker-zeppelin)
- [Github: Docker Hadoop Demo](https://github.com/silicon-valley-data-science/docker-hadoop-demo)